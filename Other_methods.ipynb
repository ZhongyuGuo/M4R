{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Other methods.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGxTZTSCzKYuxdxZZ4T0Bn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhongyuGuo/M4R/blob/main/Other_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqcGnZQppIPs"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcY44nw_pN3F",
        "outputId": "215d9d68-f87f-491e-e665-5fff7789e9e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "df=pd.read_csv(\"/content/drive/My Drive/M4R/papers2019_200000.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mSyUsEX5TNW"
      },
      "source": [
        "TRAIN_FRACTION=0.7"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCqdZoav5IW5"
      },
      "source": [
        "# List of categories\n",
        "catlist=['math','cs','quant-ph','hep-ex','hep-th','astro-ph','nucl-ex','nucl-th']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqc837yi5Jbk"
      },
      "source": [
        "# Categories to classify\n",
        "cat1=catlist[6]\n",
        "cat2=catlist[7]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVjKoeWn4nhJ"
      },
      "source": [
        "# Obtain corresponding abstarcts\n",
        "df1=df[df['categories']==cat1][0:1500].reset_index(drop=True)\n",
        "df2=df[df['categories']==cat2][0:1500].reset_index(drop=True)\n",
        "text=df1.append(df2).reset_index(drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so2HLean4pb_"
      },
      "source": [
        "def format_text(text):\n",
        "    \"\"\"Add spaces around punctuation and remove references to images/citations.\"\"\"\n",
        "\n",
        "    # Add spaces around punctuation\n",
        "    text = re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', text)\n",
        "\n",
        "    # Remove references to figures\n",
        "    text = re.sub(r'\\((\\d+)\\)', r'', text)\n",
        "\n",
        "    text=re.sub(' the ',' ',text)\n",
        "    text=re.sub(' of ',' ',text)\n",
        "    text=re.sub(' and ',' ',text)\n",
        "    text=re.sub(' a ',' ',text)\n",
        "    text=re.sub(' in ',' ',text)\n",
        "    text=re.sub(' to ',' ',text)\n",
        "    text=re.sub(' with ',' ',text)\n",
        "    text=re.sub(' for ',' ',text)\n",
        "    text=re.sub(' by ',' ',text)\n",
        "    text=re.sub(' on ',' ',text)\n",
        "    text=re.sub(' as ',' ',text)\n",
        "    text=re.sub(' an ',' ',text)\n",
        "    text=re.sub(' at ',' ',text)\n",
        "    text=re.sub(' we ',' ',text)\n",
        "    text=re.sub(' is ',' ',text)\n",
        "    text=re.sub(' this ',' ',text)\n",
        "    text=re.sub(' are ',' ',text)\n",
        "    text=re.sub(' which ',' ',text)\n",
        "    text=re.sub(' be ',' ',text)\n",
        "    text=re.sub(' it ',' ',text)\n",
        "    text=re.sub(' that ',' ',text)\n",
        "    text=re.sub(' from ',' ',text)\n",
        "    text=re.sub(' can ',' ',text)\n",
        "    text=re.sub(' these ',' ',text)\n",
        "    text=re.sub(' our ',' ',text)\n",
        "    text=re.sub(' has ',' ',text)\n",
        "    text=re.sub(' have ',' ',text)\n",
        "    text=re.sub('.We ','.',text)\n",
        "    text=re.sub('.That ','.',text)\n",
        "    text=re.sub('.The ','.',text)\n",
        "    text=re.sub('.From ','.',text)\n",
        "    text=re.sub('.Our ','.',text)\n",
        "    text=re.sub('.In ','.',text)\n",
        "    text=re.sub('.These ','.',text)\n",
        "    text=re.sub('.This ','.',text)\n",
        "    text=re.sub(',that ',',',text)\n",
        "\n",
        "    # Remove double spaces\n",
        "    text = re.sub(r'\\s\\s', ' ', text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d83DgRIU4qxT"
      },
      "source": [
        "formatted = []\n",
        "\n",
        "# Iterate through all the original abstracts\n",
        "for a in text['abstracts']:\n",
        "    formatted.append(format_text(a))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLZcRzET4sUE"
      },
      "source": [
        "def make_sequences(texts,\n",
        "                   training_length=50,\n",
        "                   lower=True,\n",
        "                   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
        "    \"\"\"Turn a set of texts into sequences of integers\"\"\"\n",
        "\n",
        "    # Create the tokenizer object and train on texts\n",
        "    tokenizer = Tokenizer(lower=lower, filters=filters)\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "\n",
        "    # Create look-up dictionaries and reverse look-ups\n",
        "    word_idx = tokenizer.word_index\n",
        "    idx_word = tokenizer.index_word\n",
        "    num_words = len(word_idx) + 1\n",
        "    word_counts = tokenizer.word_counts\n",
        "\n",
        "    print(f'There are {num_words} unique words.')\n",
        "\n",
        "    # Convert text to sequences of integers\n",
        "    features = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    categories=list(set(text['categories'].values))\n",
        "    labels=np.zeros(len(text))\n",
        "    for i in range(len(text)):\n",
        "      ind=categories.index(text.iloc[i,1])\n",
        "      labels[i]=ind\n",
        "    return word_idx, idx_word, num_words, word_counts, features,labels\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEe8McZG4tuc",
        "outputId": "9838a63c-de28-480e-e8fb-d2b482bc6b09"
      },
      "source": [
        "TRAINING_LENGTH = 50\n",
        "filters = '.,!\"#$%&()*+/:<=>@[\\\\]^_`{|}~\\t\\n'\n",
        "word_idx, idx_word, num_words, word_counts,features,labels = make_sequences(\n",
        "    formatted, TRAINING_LENGTH, lower=True, filters=filters)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14260 unique words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cMIx6vV4vrk"
      },
      "source": [
        "#Make all sequences to same length\n",
        "pad = len(max(features, key=len))\n",
        "features=[i + [0]*(pad-len(i)) for i in features]\n",
        "features1=np.array(features)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vkDCxzg40fi"
      },
      "source": [
        "# Define Training and Test sets\n",
        "X_input=np.zeros([2000,len(features[0])])\n",
        "X_input[0:1000,:]=features1[0:1000,:]\n",
        "X_input[1000:2000]=features1[1500:2500,:]\n",
        "X_test=np.zeros([1000,len(features[0])])\n",
        "X_test[0:500,:]=features1[1000:1500,:]\n",
        "X_test[500:1000]=features1[2500:3000,:]\n",
        "y_input=np.zeros(2000)\n",
        "y_input[0:1000]=labels[0:1000]\n",
        "y_input[1000:2000]=labels[1500:2500]\n",
        "y_test=np.zeros([1000])\n",
        "y_test[0:500]=labels[1000:1500]\n",
        "y_test[500:1000]=labels[2500:3000]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQQu0qSs45PK"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def create_train_valid(features,\n",
        "                       labels,\n",
        "                       train_fraction=TRAIN_FRACTION):\n",
        "    \"\"\"Create training and validation features and labels.\"\"\"\n",
        "\n",
        "    # Randomly shuffle features and labels\n",
        "    features, labels = shuffle(features, labels, random_state=RANDOM_STATE)\n",
        "\n",
        "    # Decide on number of samples for training\n",
        "    train_end = int(train_fraction * len(labels))\n",
        "\n",
        "    train_features = np.array(features[:train_end])\n",
        "    valid_features = np.array(features[train_end:])\n",
        "\n",
        "    train_labels = labels[:train_end]\n",
        "    valid_labels = labels[train_end:]\n",
        "\n",
        "    # Convert to arrays\n",
        "    X_train, X_valid = np.array(train_features), np.array(valid_features)\n",
        "    y_train, y_valid = np.array(train_labels), np.array(valid_labels)\n",
        "\n",
        "    # Memory management\n",
        "    import gc\n",
        "    gc.enable()\n",
        "    del features, train_features, labels, valid_features, train_labels, valid_labels\n",
        "    gc.collect()\n",
        "\n",
        "    return X_train, X_valid, y_train, y_valid"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RqgkkGm48R5"
      },
      "source": [
        "RANDOM_STATE = 50\n",
        "X_train, X_valid, y_train, y_valid = create_train_valid(X_input, y_input)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy6-zBAN_SSB"
      },
      "source": [
        "#Preprecoess the training data and test features\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_scaled=scaler.transform(X_train)\n",
        "scaler1 = preprocessing.StandardScaler().fit(X_test)\n",
        "X_test_scaled=scaler1.transform(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjzDhdltRvOO"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktv-r5Hd9Orn"
      },
      "source": [
        "# Parameters to search for the optimal ones\n",
        "parameters_LR = {'C':np.linspace(0.001,0.01,19),'solver':['lbfgs','sag','liblinear','newton-cg']}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgKqxUIH_aHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb3131d-ac63-4053-9252-0ac6d800aeb9"
      },
      "source": [
        "#GridSeach for Logistic Regression\n",
        "lr=LogisticRegression(max_iter=200000)\n",
        "lr_optimal=GridSearchCV(lr,parameters_LR,cv=5,n_jobs=4)\n",
        "lr_optimal.fit(X_train_scaled,y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=200000, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=4,\n",
              "             param_grid={'C': array([0.001 , 0.0015, 0.002 , 0.0025, 0.003 , 0.0035, 0.004 , 0.0045,\n",
              "       0.005 , 0.0055, 0.006 , 0.0065, 0.007 , 0.0075, 0.008 , 0.0085,\n",
              "       0.009 , 0.0095, 0.01  ]),\n",
              "                         'solver': ['lbfgs', 'sag', 'liblinear', 'newton-cg']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IediMR-YCCNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea91fc6f-ffcb-4308-b62d-0647358889a1"
      },
      "source": [
        "print('Best params:',lr_optimal.best_params_)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: {'C': 0.0025, 'solver': 'lbfgs'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMjTDi715X2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d75dcc8-cebf-4e1d-a48a-231053472b76"
      },
      "source": [
        "#Show accracy on train and test set\n",
        "training_predict =lr_optimal.predict(X_train_scaled)\n",
        "test_predict=lr_optimal.predict(X_test_scaled)\n",
        "from sklearn.metrics import accuracy_score\n",
        "train_acc=accuracy_score(y_train,training_predict)\n",
        "test_acc=accuracy_score(y_test,test_predict)\n",
        "print('Train acc: ',train_acc*100)\n",
        "print('Test acc: ',test_acc*100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  75.5\n",
            "Test acc:  72.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYkQrmKB67qO"
      },
      "source": [
        "## RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M0Wae4gEkz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4130c0f-a43e-4733-e700-7f4cae0d474e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Parameter to search for thr optimal ones\n",
        "parameters_RF = {'n_estimators':np.linspace(10,120,12,dtype='int'),'max_depth':np.linspace(10,50,5,dtype='int'),'max_features':np.linspace(5,10,5,dtype='int')}\n",
        "rfc=RandomForestClassifier()\n",
        "rfc_optimal=GridSearchCV(rfc,parameters_RF,cv=5,n_jobs=8)\n",
        "rfc_optimal.fit(X_train_scaled,y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=8,\n",
              "             param_grid={'max_depth': array([10, 20, 30, 40, 50]),\n",
              "                         'max_features': array([ 5,  6,  7,  8, 10]),\n",
              "                         'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJtoEz4vG8hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74cda51-4e25-4e7a-b775-eb2a85623ee4"
      },
      "source": [
        "print('Hyperparameter with biggest impact:',rfc_optimal.best_params_)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameter with biggest impact: {'max_depth': 50, 'max_features': 5, 'n_estimators': 120}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvzzA-HdG2Az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bffc4a9-9b04-41f9-917c-7cbffee14f57"
      },
      "source": [
        "#Show train and test accuracy\n",
        "training_predict =rfc_optimal.predict(X_train_scaled)\n",
        "test_predict=rfc_optimal.predict(X_test_scaled)\n",
        "train_acc=accuracy_score(y_train,training_predict)\n",
        "test_acc=accuracy_score(y_test,test_predict)\n",
        "print('Train acc: ',train_acc*100)\n",
        "print('Test acc: ',test_acc*100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  100.0\n",
            "Test acc:  73.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxwY-1i5R_0a"
      },
      "source": [
        "### Supported Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtLII_NBAG_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e5b620-ac4b-4ed3-e820-736c2333b5b7"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "parameters_SVM = {'kernel':('linear','poly','rbf'),'degree':np.linspace(2,8,7),'gamma':('scale','auto'),'C':np.linspace(0.001,0.01,10)}\n",
        "svm=SVC()\n",
        "svm_optimal=GridSearchCV(svm,parameters_SVM,cv=5,n_jobs=8)\n",
        "svm_optimal.fit(X_train_scaled,y_train)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=8,\n",
              "             param_grid={'C': array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
              "       0.01 ]),\n",
              "                         'degree': array([2., 3., 4., 5., 6., 7., 8.]),\n",
              "                         'gamma': ('scale', 'auto'),\n",
              "                         'kernel': ('linear', 'poly', 'rbf')},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3geMi2_iRiIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5334bf13-67d5-46f7-cdf9-a65354725592"
      },
      "source": [
        "print('Hyperparameter with biggest impact:',svm_optimal.best_params_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameter with biggest impact: {'C': 0.001, 'degree': 2.0, 'gamma': 'scale', 'kernel': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IhUJSnbRq0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51cb3e6-70c0-474e-c9b1-b9fb078736d0"
      },
      "source": [
        "\n",
        "training_predict =svm_optimal.predict(X_train_scaled)\n",
        "test_predict=svm_optimal.predict(X_test_scaled)\n",
        "train_acc=accuracy_score(y_train,training_predict)\n",
        "test_acc=accuracy_score(y_test,test_predict)\n",
        "print('Train acc: ',train_acc*100)\n",
        "print('Test acc: ',test_acc*100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  74.57142857142857\n",
            "Test acc:  71.89999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}