{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Shakespeare Dataset.ipynb","provenance":[{"file_id":"1aejEcUkJJEYbXRXR8RyiTLUGIn7mt914","timestamp":1622449762927},{"file_id":"1OvAgdfmJ3ruNNbbyjA7CHnqZbcNMmXfm","timestamp":1622351894598},{"file_id":"1tbXaGalHR6LkoaIE_lJZWLWKWgxV6nUY","timestamp":1605764652923}],"collapsed_sections":[],"authorship_tag":"ABX9TyM4lGIGw5bhdKFoEBu4hbni"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"gRe6U60z0dd0","executionInfo":{"status":"ok","timestamp":1622710894161,"user_tz":-480,"elapsed":2085,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKCKQxDGyx6q","executionInfo":{"status":"ok","timestamp":1622710894163,"user_tz":-480,"elapsed":8,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n","# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3EV10mt0i3w","executionInfo":{"status":"ok","timestamp":1622710894163,"user_tz":-480,"elapsed":7,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"66bbea85-520f-456c-8a20-1b651c7fac5e"},"source":["# Take a look at the first 250 characters in text\n","print(text[:250])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cLfSQHO0nNI","executionInfo":{"status":"ok","timestamp":1622710894163,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"fcc8ac93-17f9-4c15-dc10-ebedc0b8fbd2"},"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print('{} unique characters'.format(len(vocab)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["65 unique characters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"udMuvPyO0qSQ","executionInfo":{"status":"ok","timestamp":1622710894669,"user_tz":-480,"elapsed":509,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","text_as_int = np.array([char2idx[c] for c in text])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwIOTJsvwcp7","executionInfo":{"status":"ok","timestamp":1622710894669,"user_tz":-480,"elapsed":8,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"f167097d-0c02-4391-cc23-d759f2cd3da2"},"source":["# Show how the first 13 characters from the text are mapped to integers\n","print('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t0bIS8MzwfDg","executionInfo":{"status":"ok","timestamp":1622710894670,"user_tz":-480,"elapsed":8,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["# The maximum length sentence you want for a single input in characters\n","seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","# Create training examples / targets\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9YWiT3twhtL","executionInfo":{"status":"ok","timestamp":1622710894671,"user_tz":-480,"elapsed":9,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"ac81956c-a28b-45d4-b41f-72f155d3c1cd"},"source":["sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for item in sequences.take(5):\n","    print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sACBgmPNwkYq","executionInfo":{"status":"ok","timestamp":1622710894671,"user_tz":-480,"elapsed":7,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["def split_input_target(chunk):\n","    input_text = chunk[:-1]\n","    target_text = chunk[1:]\n","    return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0VI3hlcwmmC","executionInfo":{"status":"ok","timestamp":1622710894671,"user_tz":-480,"elapsed":7,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"65158e9c-2b48-4965-d4fe-4ae6654fc9f9"},"source":["for input_example, target_example in  dataset.take(1):\n","    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rMYTok1XwsMe","executionInfo":{"status":"ok","timestamp":1622710894672,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKuJI_f8wyh6","executionInfo":{"status":"ok","timestamp":1622710894672,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5X-GHsTw43c","executionInfo":{"status":"ok","timestamp":1622710894672,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                                  batch_input_shape=[batch_size, None]),\n","        tf.keras.layers.LSTM(rnn_units,\n","                            return_sequences=True,\n","                            stateful=True,\n","                            recurrent_initializer='glorot_uniform'),\n","        tf.keras.layers.Dense(vocab_size)\n","    ])\n","    return model"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"lV6Ao1vYw6vb","executionInfo":{"status":"ok","timestamp":1622710895081,"user_tz":-480,"elapsed":414,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["model = build_model(\n","    vocab_size=len(vocab),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units,\n","    batch_size=BATCH_SIZE)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n10hLKYnw_6P","executionInfo":{"status":"ok","timestamp":1622710895081,"user_tz":-480,"elapsed":4,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"15fbce42-eba1-4ef6-8f1e-8970204507e0"},"source":["model.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (64, None, 256)           16640     \n","_________________________________________________________________\n","lstm (LSTM)                  (64, None, 1024)          5246976   \n","_________________________________________________________________\n","dense (Dense)                (64, None, 65)            66625     \n","=================================================================\n","Total params: 5,330,241\n","Trainable params: 5,330,241\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v0UJhjpxxERM","executionInfo":{"status":"ok","timestamp":1622710895081,"user_tz":-480,"elapsed":3,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["# Define Loss function\n","def loss(labels, logits):\n","    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1I4-dVTzWD0","executionInfo":{"status":"ok","timestamp":1622710895082,"user_tz":-480,"elapsed":4,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["model.compile(optimizer='adam', loss=loss)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSECs6oKzYIv","executionInfo":{"status":"ok","timestamp":1622710895082,"user_tz":-480,"elapsed":3,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}}},"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"PAmSm0XUzaLC","executionInfo":{"status":"error","timestamp":1622710911927,"user_tz":-480,"elapsed":16848,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"7ce7dad1-a2fc-4427-b095-01366ec8a6c3"},"source":["EPOCHS = 10\n","history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","  1/172 [..............................] - ETA: 27:25 - loss: 4.1756"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-7efaa78b2913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"pRhzuWxHziJU"},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1, None]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8NGfv48zjv5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622625130971,"user_tz":-480,"elapsed":15,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"014ae89b-20bb-4a1a-ddc5-862a7071230f"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (1, None, 256)            16640     \n","_________________________________________________________________\n","lstm_1 (LSTM)                (1, None, 1024)           5246976   \n","_________________________________________________________________\n","dense_1 (Dense)              (1, None, 65)             66625     \n","=================================================================\n","Total params: 5,330,241\n","Trainable params: 5,330,241\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VcNQhJc8zrS5"},"source":["def generate_text(model, start_string):\n","    # Evaluation step (generating text using the learned model)\n","\n","    # Number of characters to generate\n","    num_generate = 1000\n","\n","    # Converting our start string to numbers (vectorizing)\n","    input_eval = [char2idx[s] for s in start_string]\n","    input_eval = tf.expand_dims(input_eval, 0)\n","\n","    # Empty string to store our results\n","    text_generated = []\n","\n","    # Low temperature results in more predictable text.\n","    # Higher temperature results in more surprising text.\n","    # Experiment to find the best setting.\n","    temperature = 1.0\n","\n","    # Here batch size == 1\n","    model.reset_states()\n","    for i in range(num_generate):\n","        predictions = model(input_eval)\n","        # remove the batch dimension\n","        predictions = tf.squeeze(predictions, 0)\n","\n","        # using a categorical distribution to predict the character returned by the model\n","        predictions = predictions / temperature\n","        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","        # Pass the predicted character as the next input to the model\n","        # along with the previous hidden state\n","        input_eval = tf.expand_dims([predicted_id], 0)\n","\n","        text_generated.append(idx2char[predicted_id])\n","\n","    return (start_string + ''.join(text_generated))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VbLM7uFzvji","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622625142005,"user_tz":-480,"elapsed":11045,"user":{"displayName":"Tiger Guo","photoUrl":"","userId":"07418486884664043682"}},"outputId":"519a5d05-900a-4d75-ac80-a1ce58bc3997"},"source":["print(generate_text(model, start_string=u\"ROMEO: \"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ROMEO: XENNENIBENICIIANUSSANCA:\n","Long makes, my coains that I shod our mistress,\n","There he was as end, and their yield you on't.\n","\n","Provost:\n","Yet hither not some means me your appealth.\n","O, and my fash, little lords about him?\n","\n","CURIOLANUS:\n","Sir, there's made a craving ladf in just,\n","He stolend, and so fitued and unwilling.\n","\n","KING EDWARD IV:\n","Why, then he wakes, thou holdst near; though she should be\n","some advanced by the honour with my heg;\n","Against the wallost captain reason lay wales make much grief\n","To wash the Dudbish choice. Goddom more.\n","\n","OXFORD:\n","O, the loss, God rence! what doth she chasping vesame,\n","O, he shall receive my country's lord:\n","Pale Edward more to wonser; who, aught reways\n","The palace of your incill at Tybalt and all,\n","Would be my weakned painted foolmy have a babe,\n","I cannot hold upon too good word; all glistening\n","glad! it is a\n","gentleman, and a goid but only censured? hurlity\n","in the confesses to such every man,\n","Bid them many-son of man?\n","\n","MARCIUS:\n","Maria, my lord.\n","\n","DUKE VINCENTIO:\n","A shall, you\n"],"name":"stdout"}]}]}